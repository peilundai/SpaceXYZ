{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from segmentation_models import PSPNet\n",
    "from segmentation_models import FPN\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import Linknet\n",
    "from segmentation_models.segmentation_models.backbones import get_preprocessing\n",
    "\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import spacexyz\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = \"./images/cvc/training_augmented/images\"\n",
    "train_label_path = \"./images/cvc/training_augmented/labels\"\n",
    "val_image_path = \"./images/cvc/testing/images\"\n",
    "val_label_path = \"./images/cvc/testing/labels\"\n",
    "\n",
    "n_classes = 1+7\n",
    "\n",
    "input_size = (384, 384, 3)\n",
    "output_size = (384, 384)\n",
    "\n",
    "# Unet, PSPNet, FPN, Linknet\n",
    "model_name = 'Unet'\n",
    "\n",
    "# vgg16, vgg19, resnet18, resnet34, resnet50, resnet101, resnet152, resnext50, resnext101, densenet121, densenet169, densenet201, inceptionv3, inceptionresnetv2\n",
    "backbone_name = 'resnet34'\n",
    "\n",
    "# number of 10 epoches between saving models\n",
    "n_save = 10\n",
    "\n",
    "# TODO to resize back the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "############# Read in files ########################\n",
    "####################################################\n",
    "\n",
    "train_images = spacexyz.path2filelist(train_image_path)\n",
    "train_labels = spacexyz.path2filelist(train_label_path)\n",
    "val_images = spacexyz.path2filelist(val_image_path)\n",
    "val_labels = spacexyz.path2filelist(val_label_path)\n",
    "\n",
    "assert(len(train_images) == len(train_labels))\n",
    "assert(len(val_images) == len(val_labels))\n",
    "\n",
    "n_training = len(train_images)\n",
    "n_val = len(val_images)\n",
    "print(\"Number of training images: \", n_training)\n",
    "print(\"Number of validation or testing images: \", n_val)\n",
    "\n",
    "# initialize data\n",
    "X_train = np.zeros([n_training, *input_size]).astype(np.uint8)\n",
    "y_train = np.zeros([n_training, *output_size]).astype(np.uint8)\n",
    "\n",
    "X_val = np.zeros([n_val, *input_size]).astype(np.uint8)\n",
    "y_val = np.zeros([n_val, *output_size]).astype(np.uint8)\n",
    "\n",
    "\n",
    "####################################################\n",
    "############# Read in training dataset #############\n",
    "####################################################\n",
    "\n",
    "print(\"reading in \", n_training, \" training samples...\")\n",
    "for i in range(n_training):\n",
    "    print(i, end='.')\n",
    "    t_image = cv2.imread(join(train_image_path, train_images[i]))\n",
    "    t_label = cv2.imread(join(train_label_path, train_labels[i]))\n",
    "    X_train[i,:,:,:] = cv2.resize(t_image, input_size[:2])\n",
    "    y_train[i,:,:] = cv2.resize(t_label[:,:,0], output_size[:2], interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=n_classes, dtype='float32')\n",
    "\n",
    "\n",
    "####################################################\n",
    "############# Read in validation dataset ###########\n",
    "####################################################\n",
    "\n",
    "print(\"reading in \", n_val, \" eval samples...\")\n",
    "for i in range(n_val):\n",
    "    print(i,end= '.')\n",
    "    v_image = cv2.imread(join(val_image_path, val_images[i]))\n",
    "    v_label = cv2.imread(join(val_label_path, val_labels[i]))\n",
    "    X_val[i,:,:,:] = cv2.resize(v_image, input_size[:2])\n",
    "    y_val[i,:,:] = cv2.resize(v_label[:,:,0], output_size[:2], interpolation=cv2.INTER_NEAREST)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=n_classes, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "############# Preprocess data ######################\n",
    "####################################################\n",
    "\n",
    "preprocessing_fn = get_preprocessing('resnet34')\n",
    "x = preprocessing_fn(X_train)\n",
    "\n",
    "## callback function to evaluate test data at the end of each training epoch\n",
    "\n",
    "class TestCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "\n",
    "####################################################\n",
    "############# Set model parameters #################\n",
    "####################################################\n",
    "\n",
    "if model_name = 'Unet':\n",
    "    model = Unet(backbone_name=backbone_name, classes=n_classes, activation='softmax')\n",
    "elif model_name = 'PSPNet':\n",
    "    model = PSPNet(backbone_name=backbone_name, classes=n_classes, activation='softmax')\n",
    "elif model_name = 'FPN':\n",
    "    model = FPN(backbone_name=backbone_name, classes=n_classes, activation='softmax')\n",
    "elif model_name = 'Linknet'\n",
    "    model = Linknet(backbone_name=backbone_name, classes=n_classes, activation='softmax')\n",
    "else:\n",
    "    print('Please provide the right model name')\n",
    "\n",
    "model.compile('Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy']) \n",
    "\n",
    "\n",
    "####################################################\n",
    "############# Training model #######################\n",
    "####################################################\n",
    "\n",
    "for i in range(n_save):\n",
    "    print('==============================')\n",
    "    print('in iteration: ', i+1)\n",
    "    print('==============================')\n",
    "    \n",
    "    model.fit(x, y_train,  validation_data=(X_val, y_val), callbacks=[TestCallback((X_val, y_val))], batch_size=1, epochs=10, verbose=True)\n",
    "    model_name = 'Unet_epoch_'+str(10*(i+1))+'.h5'\n",
    "    \n",
    "    print('==============================')\n",
    "    print('saving model after epoch ', (i+1)*10)\n",
    "    print('==============================')\n",
    "    \n",
    "    save_name = model_name+\"_epoch_\"+str(10*(i+1))+\".h5\"\n",
    "    model.save(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(X_val, batch_size=None, verbose=1, steps=None)\n",
    "\n",
    "# import imgaug as ia\n",
    "# from imgaug import augmenters as iaa\n",
    "\n",
    "# one_hot = spacexyz.onehot2ind(pred)\n",
    "\n",
    "# k=19\n",
    "# label = one_hot[k,:,:]\n",
    "# segmap = label.astype(np.int32)\n",
    "# segmap = ia.SegmentationMapOnImage(segmap, shape=(512, 512), nb_classes=1+6)\n",
    "# plt.imshow(segmap.draw_on_image(X_val[k,:,:,:]))\n",
    "# cv2.imwrite('messigray.png',segmap.draw_on_image(X_val[k,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_py36]",
   "language": "python",
   "name": "conda-env-tensorflow_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
